install.packages("downloader")
install.packages("Rlinkedin")
install.packages("Rmarkdown")
install.packages("rmarkdown")
library(Rlinkedin)
in.auth <- inOAuth()
in.auth <- inOAuth("Estat Jr. - Industria - Client Finder", "787wf8qb6n3qok", "vSL3kQP2WEWfKyxE")
in.auth <- inOAuth("Estat Jr. - Industria - Client Finder", "787wf8qb6n3qok", "vSL3kQP2WEWfKyxE")
?searchPeople
search.results <- searchPeople(token = in.auth, keywords = "gerente", country_code = "br", postal_code = "13083-859", distance = 60)
search.results <- searchPeople(token = in.auth, keywords = "gerente", country_code = "br", postal_code = "13083-859", distance = 60)
getProfile(token = in.auth, id = 634719143)
install.packages("TeachingDemos")
install.packages("printr")
install.packages("downloader")
?hist
h <- hist(DistribuicaoMediaAmostral(ID=Populacao$id,Y=Populacao$Y,n=30,reposicao="sim",B=3000),main="Distribuição da Média Amostral",ylab=" ", xlab="Média Amostral",col="lightblue",probability = TRUE)
n=30
---
title: "Atividade 8"
runtime: shiny
output: html_document
---
### Introdução
Imagine que você esteja interessado em saber a distância média, em km, da moradia de cada aluno até a UNICAMP. Imagine também uma situação em que não será possível entrevistar todos eles. O que fazer?
Podemos obter uma estimativa da distância média perguntando apenas para uma parte da população de interesse. Mas, quão boa seria esta estimativa? Ela é precisa? A forma como coletamos "parte da população" influencia na precisão desta estimativa?
Nesta atividade, o objetivo é investigar os meios pelos quais as estatísticas de uma amostra aleatória de dados podem servir como estimativas pontuais de parâmetros populacionais. Estamos interessados em formular uma distribuição amostral de nossa estimativa para aprender sobre as propriedades da estimativa, como sua distribuição.
Vamos considerar um estudo de simulação a partir de população para avaliar algumas propriedades da estimativa.
Um questionário sobre distância de casa até a Unicamp foi respondido por alguns alunos/professores. As pessoas que responderam a este questionário serão consideradas como nossa população (apenas para propósito das simulações nesta atividade). Na prática, dificilmente temos informação completa sobre a população, de maneira que temos que utilizar amostragem e inferência estatísticas para obter informações sobre a população.
```{r echo=FALSE}
library(downloader)
download("https://docs.google.com/spreadsheets/d/1QcKL4yKPKfpEp_w-IjXN7AUrgQfDYyXwXQBcy-dX_XU/pub?gid=1930158026&single=true&output=csv","distancia.csv")
distancia <- read.csv("distancia.csv")
# convertendo número com separador decimal de virgula para ponto
distancia$km <- as.numeric(gsub(pattern=",",replacement=".",distancia$Qual.a.distância..em.km..da.sua.casa.até.a.UNICAMP.))
```
### Parte 1
Considere a seguinte população: pessoas da Unicamp que responderam à pergunta: "Qual a distância, em km, da sua casa até a UNICAMP?". Denotaremos cada aluno por um número, $i$ ($i=1,2,\ldots,`r length(distancia$km)`$) e a resposta de cada aluno por $Y_i$.
O histograma a seguir apresenta a distribuição das distâncias respondidas.
```{r,echo=FALSE}
hist(distancia$km,breaks=20,col="lightblue",ylab="Frequência",xlab="Distância",main="Distância de casa até a UNICAMP")
### conjunto de dados em que a primeira coluna indica o aluno e a segunda coluna a resposta dele
Populacao <- data.frame(id=1:length(distancia$km),Y=distancia$km)
dist_media <- mean(Populacao$Y)
dist_var <- sum((Populacao$Y - dist_media)^2) / dim(Populacao)[1]
```
A distância média de casa até a UNICAMP para estes alunos é $\bar{Y}=\frac{1}{N}\sum_{i=1}^NY_i=`r round(dist_media,2)`$.
A variância populacional é definida por: $\sigma^2=\frac{1}{N}\sum_{i=1}^N(Y_i-\bar{Y})^2=`r round(dist_var,2)`$.
### Parte 2
Agora, **imagine que toda esta informação nos seja desconhecida**. Vamos, então, coletar uma amostra aleatória dentre os alunos da população (os `r length(distancia$km)` alunos). O primeiro passo para coletar uma amostra aleatória a partir de uma população é listar todos os elementos, $N$, da mesma. A partir da lista devemos escolher, aleatoriamente, uma amostra de tamanho $n$. Deve-se definir, também, se a seleção aleatória será com ou sem reposição dos elementos da população.
Temos $N=`r dim(Populacao)[1]`$ alunos. Há $N^n$ maneiras de amostrarmos $n$ elementos dentre $N$ com reposição. Temos $\binom{N}{n}$ maneiras de amostrarmos $n$ elementos dentre $N$ sem reposição.
Considere que uma amostra tenha sido feita e que, para cada aluno amostrado, tenhamos coletado a informação desejada, $Y_i^*$. Como temos interesse na distância média da população toda, calculamos também a média das distâncias observadas na amostra, denotando por $\bar{Y}^*$.
As respostas da população, $Y_i$, nos são desconhecidas, porém podemos pensar que são "fixas". Já a média obtida através de uma amostra aleatória, $\bar{Y}^*$, muda cada vez que selecionarmos uma amostra novamente. $\bar{Y}^*$ é uma variável aleatória, portanto tem distribuição de probabilidade, esperança e variância. Para estudarmos sua distribuição de probabilidade, devemos considerar todas as $\binom{N}{n}$ amostras possíveis (caso sem reposição), calcular a distância média para cada uma dessas amostras e então, calcular a probabilidade de cada valor possível que a média da amostra pode assumir. Com a distribuição definida, basta calcular esperança e variância.
Como até para um exemplo com uma população reduzida a número de amostras é bastante grande, iremos usar simulação para estudar a distribuição de probabilidade da média amostral, $\bar{Y}^*$.
Para efeitos de simulação, usaremos a função a seguir, que seleciona aleatoriamente uma amostra de tamanho $n$ a partir de dados completos de uma população de tamanho $N$.
```{r}
Simulacao <- function(ID,Y,n){
idAmostrado <- sample(x=ID,size=n,replace=TRUE)
YAmostrado <- Y[idAmostrado]
Media <- mean(YAmostrado)
return(list(idAmostrado=idAmostrado,YAmostrado=YAmostrado,Media=Media))
}
```
Portanto, se quisermos simular uma amostra aleatória com reposição de tamanho $n=20$ da população considerada, com reposição, usamos o comando:
```{r}
Simulacao(ID=Populacao$id,Y=Populacao$Y,n=20)
```
Note que a função retorna uma lista com 3 elementos: o identificador de cada aluno da população selecionado na amostra, a resposta do aluno e a média da amostra. Para estudar a distribuição de probabilidade de $\bar{Y}^*$ estamos interessados apenas no terceiro elemento desta lista de resultados.
A função a seguir repete $B$ vezes a simulação de seleção de amostra aleatória de tamanho $n$ a partir da população:
```{r}
DistribuicaoMediaAmostral <- function(ID,Y,n,B) {
MediaAmostral <- matrix(NA,ncol=1,nrow=B)
for (b in 1:B) {
MediaAmostral[b] <- Simulacao(ID,Y,n)[[3]] # seleciona o terceiro item da lista
}
return(MediaAmostral=MediaAmostral)
}
```
### Parte 3
Usaremos o aplicativo Shiny do RStudio para avaliar de maneira dinâmica as simulações geradas a partir das duas funções acima.
```{r,echo=FALSE,message=FALSE}
selectInput("n","Escolha o tamanho de cada amostra:", choices=c(3,5,10,15,20,25,30,35,40))
selectInput("B","Número de amostras:", choices=c(30,100,1000,2000,3000))
```
```{r,echo=FALSE,message=FALSE}
renderPlot(hist(DistribuicaoMediaAmostral(ID=Populacao$id,Y=Populacao$Y,n=as.numeric(input$n),B=as.numeric(input$B)),main="Distribuição da Média Amostral",ylab="Frequência", xlab="Média Amostral",col="lightpink"))
options=list(width="100%", height="100%")
```
### Parte 4
Para resumir todos os casos em uma única tabela, iremos simular 3000 amostras para cada caso combinação de tamanho amostral. Para cada caso, iremos calcular a média das 3000 médias obtidas e também calculamos a variância amostral das 3000 médias obtidas.
Na disciplina ME430 - Técnicas de Amostragem, vocês irão verificar que a variância amostral teórica é igual $\sigma^2/n$.
```{r,echo=FALSE}
casos <- c(3,5,10,15,20,25,30,35,40)
Resultados <- sapply(casos,function(x) DistribuicaoMediaAmostral(ID=Populacao$id,Y=Populacao$Y,n=x,B=3000))
MediaAmostral <- colMeans(Resultados)
VarianciaAmostral <- apply(Resultados,2,var)
BB <- data.frame(n=casos,MediaAmostral=round(MediaAmostral,2),VarianciaAmostral=round(VarianciaAmostral,2))
sigma2 <- VarianciaAmostral * (BB$n - 1)/BB$n # $\sigma^2, variancia populacional$
BB$VarianciaAmostralTeorica <- round(sigma2/BB$n,2)
colnames(BB) <- c("Tamanho da Amostra","Média Amostral: Média das 3000 Médias", "Variância Amostral: Variância das 3000 Médias","Variância Amostral Teórica")
library(printr)
BB
```
### Parte 5
Observe os histogramas obtidos para $B=3000$ simulações para cada caso (combinação de tamanho amostral e tipo de seleção de amostra, usando o aplicativo Shiny acima). O que você nota com relação à distribuição de probabilidade da média amostral conforme o tamanho amostral aumenta. Ela se aproxima de alguma distribuição conhecida? Discuta.
Nós notamos que a distribuição de probabilidade da média amostral vai se aproximando da distribuição normal.
Assim vemos que quanto maior o conjunto de amostras temos um menor erro na distribuição amostral, o inverso também é válido.
### Parte 6
Na simulação, fizemos $3000$ amostras de tamanho $n$ e estudamos propriedades do estimador utilizado: a média. Agora, pense no caso real, em que você não conhece a população e irá fazer uma amostra.  Note que, no caso real, só iremos fazer **uma** amostra de tamanho $n$. Portanto, obteremos apenas uma média amostral: aquela da amostra que coletamos.
* A variância teórica, no caso em que não conhecemos a população, é possível de ser calculada? Explique.
Não, pois não conseguimos definir a média amostral ou o desvio padrão da população, assim sendo impossível de calcula-la.
* Qual a utilidade de calcularmos a variância teórica a partir de dados simulados? O que podemos aprender, através da variância teórica, sobre a estimativa do parâmetro de interesse? Discuta e coloque no contexto do problema proposto no início do exercício.
Supondo que a distribuição se aproxima da distribuição normal, com as simulações podemos medir se nossa média amostral está próxima da distribuição simulada, assim nos dizendo se é um conjunto amostral bem definido.
### Parte 7
**Teorema Central do Limite:** Para uma amostra aleatória simples $X_{1},...,X_{n}$ coletada de uma população com esperança $\mu$ e variância $\sigma^{2}$, a distribuição amostral de $\bar{X}_{n}$ aproxima-se de uma **distribuição Normal** de média $\mu$ e variância $\frac{\sigma^{2}}{n}$, quando $n$ for suficientemente grande.
Portanto, utilizando o TCL, sabemos como se comportará a média amostral, $\bar{X_n}$.
Apresente o histograma de probabilidade da média amostral para $B=3000$ simulações para um tamanho amostral da sua escolha e plano amostral com reposição. No mesmo gráfico, apresente a curva da distribuição normal para a qual a distribuição da média am
h <- hist(DistribuicaoMediaAmostral(ID=Populacao$id,Y=Populacao$Y,n=30,reposicao="sim",B=3000),main="Distribuição da Média Amostral",ylab=" ", xlab="Média Amostral",col="lightblue",probability = TRUE)
n=30
h$mean
h
h <- hist(DistribuicaoMediaAmostral(ID=Populacao$id,Y=Populacao$Y,n=30,B=3000),main="Distribuição da Média Amostral",ylab=" ", xlab="Média Amostral",col="lightblue",probability = TRUE)
n=30
h$mean
h$mids
h$equidist
---
title: "Trabalho Final"
author: "170844 Jordão Bragantini, 204186 Nicole Nogueira, 193993 Ana Paula Bianchi Rosa, 197466 Gabriel Stein"
date: "26/06/2017"
output:
pdf_document
---
## Parte 1: Mega Sena
```{r megasena, echo=FALSE}
#### coloque aqui o codigo para a Parte 1
dadosMegaSena <- read.csv("mega_sena.csv", sep = "\t")
sorteia <- function(){
bolas <- c(1:60)
x <- sample(bolas, 6)
#  x <- sort(x) # ver se roda mais rápido sem
return(x)
}
numero_sorteios = 1000 #tamanho da amostra, ou número de sorteios da megasena a serem selecionados.
alfa = 0.05
dadosSelecionados <- dadosMegaSena[sample(length(dadosMegaSena[,1]), numero_sorteios),] #escolhe aleatoriamente um número de N_sorteios sorteios da megasena do banco de dados.
### simulação
simulacao <- function(n_rodadas, n_sorteios){
n_amostra <- 6*n_sorteios
esperanca <- n_amostra/60     # frequência esperada é igual para todos os números; E_1 = E_2 = E_3 = ... = E_60.
estat_simulacao <- matrix(NA,ncol=1,nrow=n_rodadas)
for (i in 1:n_rodadas){
dados_rodada <- replicate(n_sorteios,sorteia())
observada <- sapply(c(1:60), function(x) sum(dados_rodada == x)) # frequência observada é quantas vezes cada número é sorteado.
estat_simulacao[i] <- sum(abs(esperanca - observada))
}
return(estat_simulacao)
}
estatistica_observada <- function(dados, n_sorteios) {
n_amostra <- 6 * n_sorteios
esperanca <- n_amostra / 60
observada <- sapply(c(1:60), function(x) sum(as.vector(t(dados[,-1])) == x))
estat_obs <- sum(abs(esperanca - observada))
return(estat_obs) # w_obs
}
p_value_calc <- function(w_simul, w_obs, n_rodadas){
x_simul <- sum(w_simul > w_obs)
p_value <- x_simul/n_rodadas
return(p_value)
}
amostra_piloto <- simulacao(100, numero_sorteios)
w_obs <- estatistica_observada(dadosSelecionados, numero_sorteios) # w_obs
p_valor_piloto <- p_value_calc(amostra_piloto, w_obs,100)
z_alfa <- qnorm(alfa/2, lower.tail = FALSE)
margem_de_erro <- 0.01
numero_rodadas <- (p_valor_piloto * (1 - p_valor_piloto)) / (margem_de_erro / z_alfa)^2
w_simulado <- simulacao(numero_rodadas + 1, numero_sorteios) # w_simulado
p_valor <- p_value_calc(w_simulado, w_obs , numero_rodadas)
```
#### coloque aqui o codigo para a Parte 1
dadosMegaSena <- read.csv("mega_sena.csv", sep = "\t")
sorteia <- function(){
bolas <- c(1:60)
x <- sample(bolas, 6)
#  x <- sort(x) # ver se roda mais rápido sem
return(x)
}
numero_sorteios = 1000 #tamanho da amostra, ou número de sorteios da megasena a serem selecionados.
alfa = 0.05
dadosSelecionados <- dadosMegaSena[sample(length(dadosMegaSena[,1]), numero_sorteios),] #escolhe aleatoriamente um número de N_sorteios sorteios da megasena do banco de dados.
### simulação
simulacao <- function(n_rodadas, n_sorteios){
n_amostra <- 6*n_sorteios
esperanca <- n_amostra/60     # frequência esperada é igual para todos os números; E_1 = E_2 = E_3 = ... = E_60.
estat_simulacao <- matrix(NA,ncol=1,nrow=n_rodadas)
for (i in 1:n_rodadas){
dados_rodada <- replicate(n_sorteios,sorteia())
observada <- sapply(c(1:60), function(x) sum(dados_rodada == x)) # frequência observada é quantas vezes cada número é sorteado.
estat_simulacao[i] <- sum(abs(esperanca - observada))
}
return(estat_simulacao)
}
estatistica_observada <- function(dados, n_sorteios) {
n_amostra <- 6 * n_sorteios
esperanca <- n_amostra / 60
observada <- sapply(c(1:60), function(x) sum(as.vector(t(dados[,-1])) == x))
estat_obs <- sum(abs(esperanca - observada))
return(estat_obs) # w_obs
}
p_value_calc <- function(w_simul, w_obs, n_rodadas){
x_simul <- sum(w_simul > w_obs)
p_value <- x_simul/n_rodadas
return(p_value)
}
amostra_piloto <- simulacao(100, numero_sorteios)
w_obs <- estatistica_observada(dadosSelecionados, numero_sorteios) # w_obs
p_valor_piloto <- p_value_calc(amostra_piloto, w_obs,100)
z_alfa <- qnorm(alfa/2, lower.tail = FALSE)
margem_de_erro <- 0.01
numero_rodadas <- (p_valor_piloto * (1 - p_valor_piloto)) / (margem_de_erro / z_alfa)^2
w_simulado <- simulacao(numero_rodadas + 1, numero_sorteios) # w_simulado
p_valor <- p_value_calc(w_simulado, w_obs , numero_rodadas)
library("Rfacebook")
load("token")
load("page")
post_list = vector(mode = "list", length = dim(page)[1])
for(i in 1:dim(page)[1]){
post_list[[i]] <- getPost(post = page$id[i], token = token, n = 1000)
Sys.sleep(2)
}
save(post_list, file = "post_list")
library("Rfacebook")
load("token")
load("page")
post_list = vector(mode = "list", length = dim(page)[1])
for(i in 1:dim(page)[1]){
post_list[[i]] <- getPost(post = page$id[i], token = token, n = 1000)
Sys.sleep(2)
}
save(post_list, file = "post_list")
?list
rm(post_id, post_msg, like_id, like_name, comments_id, comments_msg, commenters_id, commenters_name)
post_id <- vector(mode = "character", length = 64000)
post_msg <- vector(mode = "character", length = 64000)
like_id <- vector(mode = "list", length = 64000)
like_name <- vector(mode = "list", length = 64000)
comments_id <- vector(mode = "list", length = 64000)
comments_msg <- vector(mode = "list", length = 64000)
commenters_id <- vector(mode = "list", length = 64000)
commenters_name <- vector(mode = "list", length = 64000)
k = 1
for(i in 1:10) {
if(post_list[[i]]$post$likes_count > 0 && post_list[[i]]$post$comments_count > 0) {
post_id[k] <- post_list[[i]]$post$id
post_msg[k] <- post_list[[i]]$post$message
like_id[k] <- I(post_list[[i]]$likes$from_id)
like_name[k] <- I(post_list[[i]]$likes$from_name)
comment_id[k] <- I(post_list[[i]]$comments$id)
comment_msg[k] <- I(post_list[[i]]$comments$message)
commenters_id[k] <- I(post_list[[i]]$comments$from_id)
commenters_name[k] <- I(post_list[[i]]$comments$from_name)
k <- k + 1
}
}
x <- gsub(pattern = "^", relevants, replacement = "")
setwd("~/Documents/IC/ift/swig/docs/")
install.packages("stringi")
getwd()
ls
knitr::opts_chunk$set(echo = TRUE)
getwd()
